{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning for Data Science: Scraping Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping with Beautiful Soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Beautiful Soup?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The major concept with Beautiful Soup is that it allows you to access elements of your page by following the CSS structures. Once we grab elements, Python makes it easy to write the elements or relevant components of the elements into other files, such as a CSV, that can be stored in a database or opened in other software.\n",
    "<br>\n",
    "__First__, we have to turn the website code into a Python object. <br>\n",
    "print response.text. Then turns the text into an Python object named soup. <br>\n",
    "__Second__, the built in Python parser, which we can call using html.parser that Beautiful Soup uses to parse your text. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1. First of all, you will have to install Beautifulsoup and Requests<br>\n",
    "Beautiful Soup 4 is published through PyPi, so you can install it with pip. <br>\n",
    "> _pip install beautifulsoup4_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 and Step 3 \n",
    "- Find the URL you want to scrape \n",
    "- Define what information you want \n",
    "\n",
    "ศูนย์ข้อมูลอุบัติเหตุ www.thairsc.com/th/BigAccidentAll.aspx?l-th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response = requests.get('http://www.thairsc.com/th/BigAccidentAll.aspx?l=th')\n",
    "#print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4. Identify the structure of the sites HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "soup = bs4.BeautifulSoup(response.text, \"html.parser\")\n",
    "print(soup.prettify()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5. Write the scraping code \n",
    "Extract the data from structure of the sites HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "soup.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6. Extract the information from the “soup”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = soup.findAll(attrs={'class' : 'text-detail'})\n",
    "data[1].string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "acc_text = []\n",
    "acc_day = []\n",
    "acc_month = []\n",
    "acc_year = []\n",
    "acc_time = []\n",
    "acc_addr1 = []\n",
    "acc_addr2 = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Pattern ข้อความแจ้งอุบัติเหตุ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "re_text = re.compile(r\"อุบัติเหตุ\\s*[\\\"“]*([\\s\\w\\-\\.ก-๙]+)[\\\"”]*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Pattern วันที่เกิดอุบัติเหตุ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re_date = re.compile(r\"วันที่\\s*(\\d+)[/-](\\d+)[/-](\\d+)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Pattern เวลาเกิดเหตุ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "re_time = re.compile(r\"(เวลา|เวลาประมาณ)\\s*(\\d+\\.\\d+)\\s*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. สถานที่เกิดเหตุ (อำเภอ และ จังหวัด)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "re_addr = re.compile(r\"(อ\\.|อำเภอ|เขต)\\s*([ก-๙]+)\\s*(จ\\.|จังหวัด)\\s*([ก-๙]+)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract the information from pattern "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(1, len(data)):\n",
    "    mdate = re_date.search(data[i].string)\n",
    "    acc_day.append(mdate.group(1))\n",
    "    acc_month.append(mdate.group(2))\n",
    "    acc_year.appendmdate.group(3))\n",
    "    \n",
    "    mtime = re_time.search(data[i].string)\n",
    "    acc_time.append(mtime.group(2))\n",
    "    \n",
    "    maddr = re_addr.search(data[i].string)\n",
    "    acc_addr1.append(maddr.group(2))\n",
    "    acc_addr2.append(maddr.group(4))\n",
    "    \n",
    "    mtext = re_text.search(data[i].string)\n",
    "    acc_text.append(mtext.group(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write the information into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acc_data = {'acc_text': acc_text, \n",
    "        'acc_day': acc_day, \n",
    "        'acc_month': acc_month, \n",
    "        'acc_year': acc_year, \n",
    "        'acc_time': acc_time, \n",
    "        'acc_add1':acc_addr1, \n",
    "        'acc_add2':acc_addr2}\n",
    "\n",
    "df = pd.DataFrame(acc_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge : ศูนย์ข้อมูลอุบัติเหตุ Thai Rsc in Detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response = requests.get('http://www.thairsc.com/th/BigAccDetail.aspx?qid=47053&l=th')\n",
    "soup_2 = bs4.BeautifulSoup(response.text, \"html.parser\")\n",
    "data_detail = soup_2.find('span', class_ = 'detail')\n",
    "print(data_detail.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Your practice homework\n",
    "## Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"color: black\">\n",
    "<center>_Please get back to slide_</center>\n",
    "<hr style=\"color: black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write DataFrame to Sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Jupyter Notebook scraping_framework (autosaved) \n",
    "Python 3 \n",
    "File\n",
    "Edit\n",
    "View\n",
    "Insert\n",
    "Cell\n",
    "Kernel\n",
    "Widgets\n",
    "Help\n",
    "import sqlite3\n",
    "conn = sqlite3.connect(\"accident.db\")\n",
    "df.to_sql(\"accident\", conn, if_exists=\"replace\")\n",
    "# https://www.dataquest.io/blog/python-pandas-databases/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select all data from database (named accident)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_all = pd.read_sql_query(\"select * from accident;\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count the number of accident that occur in month 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accident_11 = pd.read_sql_query(\"select count(*) from accident where acc_month=11;\", conn)\n",
    "accident_11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"color: black\">\n",
    "<center>_Please get back to slide_</center>\n",
    "<hr style=\"color: black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Search API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pip install python-twitter\n",
    "# https://python-twitter.readthedocs.io/en/latest/installation.html\n",
    "# https://www.alexkras.com/how-to-get-user-feed-with-twitter-api-and-python/\n",
    "# Go to https://dev.twitter.com/apps/new and log in , to get secret key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from twitter import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Twitter Authentication API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "api = twitter.Api(\n",
    " consumer_key='xxxxxxxxxxxxxxxxxxxx',\n",
    " consumer_secret='xxxxxxxxxxxxxxxxxxxx',\n",
    " access_token_key='xxxxxxxxxxxxxxxxxxxx',\n",
    " access_token_secret='xxxxxxxxxxxxxxxxxxxx'\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Search by term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search = api.GetSearch(term='รถชน', lang='th',  result_type='recent', count=10000, max_id='')\n",
    "for t in search:\n",
    "    print(t.user.screen_name + ' (' + t.created_at + ')')\n",
    "    print(t.text)\n",
    "    #Add the .encode to force encoding\n",
    "    #print(t.text.encode('utf-8'))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "screen_name=[]\n",
    "created_at=[]\n",
    "twitter_text=[]\n",
    "search = api.GetSearch(term='อุบัติเหตุ', lang='th',  result_type='recent', count=10000, max_id='')\n",
    "for t in search:\n",
    "    screen_name.append(t.user.screen_name)\n",
    "    created_at.append(t.created_at)\n",
    "    twitter_text.append(t.text)\n",
    "    #Add the .encode to force encoding\n",
    "    #print(t.text.encode('utf-8'))\n",
    "\n",
    "tw_data = {'screen_name': screen_name, \n",
    "        'created_at': created_at, \n",
    "        'twitter_text': twitter_text}    \n",
    "tw_df = pd.DataFrame(tw_data)\n",
    "tw_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
